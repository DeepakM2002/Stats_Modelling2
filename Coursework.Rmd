---
title: "R Notebook"
output: html_notebook
---



```{r}
df <- read.csv("1854788.csv")
df$shape <- as.numeric(df$Shape == "Cube")

cube_val <- sum(df$Number[df$Shape =="Cube"])
cyclinder_val <- sum(df$Number) - cube_val

barplot(c(cube_val, cyclinder_val), ylab = "Number of blocks", main="Total number of blocks stacked for each shape",
  names.arg=c("Cube", "Cyclinder"))




df <- df[-c(1, 3)]

#Remaining descriptor variables are age and shape with y variable number 

data <- df[sample(1:nrow(df)),]#Shuffling the data 

#Standardising age variable
#data$Age <- (data$Age - mean(data$Age))/sd(data$Age)

y <- data$Number
x1 <- data$Age
x2 <- data$shape
N = length(df$Age)
data_train <- data[1:(0.7*N),]
data_test <- data[(0.7*N +1) :N, ]

```

```{r EDA}
library(ggplot2)
plot(x1, y, xlab = "Age", ylab= "Number")

plot(x2, y, xlab = "Shape", ylab= "Number", main="Number of blocks stacked for different shapes" )

```



```{r}
# Define the number of intervals
nintervals <- 4

# Determine the interval length
interval_length <- diff(range(x1))/nintervals

# Use findInterval() to assign each x value to an interval
intervals <- findInterval(x1, seq(min(x1), max(x1), interval_length))

# Calculate the mean y value for each interval
means <- tapply(y, intervals, mean)

# Plot the scatterplot of x and y
plot(x1, y, pch = 16, cex = 0.6, xlab = "Age", ylab = "Number", main ="Number of blocks stacked as age varies")

# Plot the mean y value for each interval
points(seq(min(x1), max(x1), interval_length), means, col = "red", pch = 16)

# Add a line connecting the mean points
lines(seq(min(x1), max(x1), interval_length), means, col = "red")

```




```{r Linear Model}
#Original Least Squares Model
ls <- lm(Number ~ Age+shape, data = data_train)
summary(ls)
plot(ls )
```

```{r Poisson}
#Canonical link is the log function 
poiss_1 <- glm(Number~ Age + shape, data = data_train, family = "poisson")
summary(poiss_1)
poiss_2 <- glm(Number~Age, data=data_train, family="poisson")
summary(poiss_2)
poiss_3 <- glm(Number~shape, data=data_train, family="poisson")
summary(poiss_3)


```
```{r confidence intervals}
beta <- coefficients(poiss_1)
x <- data.matrix(data_train[, 2:3])
X <- cbind(1, x)

mu <- exp(X%*%beta)
W <- diag(mu[c(1:56)])
var_beta <- solve(t(X)%*%W%*%X)



#Wald test

var_shape <- sqrt(var_beta[2, 2])
pnorm(var_shape)

#Confidence Interval:
age_conf <- c(3, 4, 5)
shape_conf <- c(0, 1)
for (i in age_conf){
  for (j in shape_conf){
    x_star <- c(1, i, j)
    eta_star <- x_star%*%beta
    piv <- 1.96*sqrt(t(x_star)%*%var_beta%*%x_star)
    #print(c(i, j, exp(eta_star - piv), exp(eta_star + piv)))
    print(c(i, j, exp(eta_star)))

    
  }
}
predict.glm(poiss_1, data.frame(Age = 3, shape = 1), type = "response")

```




```{r best model}
dev_1 <- deviance(poiss_1)
dev_2 <- deviance(poiss_2)
dev_3 <- deviance(poiss_3)

#Testing model 1 against model 2
vs12 <- dev_2 - dev_1
p_12 <- 1 - pchisq(vs12, df=1, lower.tail = TRUE)

vs13 <- dev_3 - dev_1
p_13 <- 1 - pchisq(vs13, df=1, lower.tail = TRUE)

x_test <- data_test[, 2:3]
y_test <- data_test[, 1]
y_1 <- predict.glm(poiss_1, newdata = x_test, type = 'response')
y_2 <- predict.glm(poiss_2, newdata = x_test, type = 'response')
y_3 <- predict.glm(poiss_3, newdata = x_test, type = 'response')

MSE_1 <- sum((y_test - y_1)**2)
MSE_2 <- sum((y_test - y_2)**2)
MSE_3 <- sum((y_test - y_3)**2)
```

```{r IWLS}

x <- data.matrix(data_train[, 2:3])
y<- data.matrix(data_train[, 1])

beta <- c(20,3, 4) #initial guess
 for (i in 1:50){
     eta <- cbind(1,x)%*%beta #estimated linear predictor
     mu <- exp(eta)  #estimated mean response
     z <- eta + (y-mu)/mu #form the adjusted variate
     w <- 1/mu #weights
     lmod <- lm(z~x, weights=w) #regress z on x with weights w
     beta <- as.numeric(lmod$coeff)#new beta
  print(beta)} #print out the beta estimate every iteration +}
```

